{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import xarray as xr\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from eodag import EODataAccessGateway\n",
    "from eodag import setup_logging\n",
    "\n",
    "from rasterio.crs import CRS\n",
    "from rioxarray.merge import merge_arrays\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import geopandas as gpd\n",
    "from sklearn import svm, tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "# from shapely.geometry import MultiPolygon\n",
    "# from shapely.geometry import shape\n",
    "\n",
    "\n",
    "# Setup Verbose Values:\n",
    "# 0: no logging and no progress bar\n",
    "# 1: no logging but progress bars displayed\n",
    "# 2: log at the INFO level\n",
    "# 3: log at the DEBUG level (even more information)\n",
    "\n",
    "setup_logging(verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EODAG - Classify\n",
    "\n",
    "EODAG (Earth Observation Data Access Gateway) is a command line tool and a Python package for searching and downloading remotely sensed images while offering a unified API for data access regardless of the data provider.\n",
    "\n",
    "EODAG gives you an easy way to access products from more than 10 providers, with more than 50 different product types (Sentinel 1, Sentinel 2, Sentinel 3, Landsat, etc.) that can be searched and downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Secrets from .env File\n",
    "secrets = dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Folders for saving Data, serializing and post processing.\n",
    "\n",
    "# Path where the Data should be stored ('c:\\\\Users\\\\theUSER\\\\eodag-data')\n",
    "root = '../eodag-data/'\n",
    "\n",
    "workspace_download = os.path.join(root,'eodag_workspace_download')\n",
    "workspace_serialize = os.path.join(root,'eodag_workspace_serialize_deserialize')\n",
    "workspace_post_process = os.path.join(root,'eodag_workspace_post_process')\n",
    "workspaces = [workspace_download, workspace_serialize, workspace_post_process]\n",
    "\n",
    "for ws in workspaces:\n",
    "    ws = os.path.abspath(ws)\n",
    "    \n",
    "    if not os.path.isdir(ws):\n",
    "        os.mkdir(ws)\n",
    "        print(f'Created Folder: {ws}')\n",
    "    else:\n",
    "        print(f'Folder already exists: {ws}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "### Configuration\n",
    "In the configuration we pass the username and password from the Copernicus Dataspace Ecosystem (CDSE) to eodag. Also we define the path for the downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure\n",
    "#Create EODAG Object and set preferred Provider\n",
    "dag = EODataAccessGateway()\n",
    "dag.set_preferred_provider(\"cop_dataspace\") # Copernicus Data Space Ecosystem\n",
    "\n",
    "dag.update_providers_config(f\"\"\"\n",
    "    cop_dataspace:\n",
    "        download:\n",
    "            outputs_prefix: {os.path.abspath(workspace_download)}\n",
    "        auth:\n",
    "            credentials:\n",
    "                username: {secrets['USER_KEY']}\n",
    "                password: {secrets['USER_SECRET']}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "### Deserialize\n",
    "Since the search is already done (see Notebook `eodag_search`) and the search result has been serialized, we are going to deserialize the search result and register it. If it is only deserialized it won't be able to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize the Search Results\n",
    "output_file = os.path.join(workspace_serialize, \"search_results3.geojson\")\n",
    "deserialized_search_results = dag.deserialize_and_register(output_file)\n",
    "\n",
    "print(f\"Got {len(deserialized_search_results)} deserialized products.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Quicklooks of Search Results\n",
    "def plot_quicklooks(products):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    for i, product in enumerate(products[:12]):\n",
    "        # This line takes care of downloading the quicklook\n",
    "        quicklook_path = product.get_quicklook()\n",
    "        \n",
    "        date = product.properties['startTimeFromAscendingNode'][:16]\n",
    "        provider = product.provider\n",
    "        tile = product.properties['title'].split('_')[5].lstrip('T')\n",
    "    \n",
    "        # Plot the quicklook\n",
    "        img = mpimg.imread(quicklook_path)\n",
    "        ax = fig.add_subplot(3, 4, i+1)\n",
    "        ax.set_title(f'Product {i}\\n{date}\\n{provider} - {tile}')\n",
    "        ax.tick_params(top=False, bottom=False, left=False, right=False,\n",
    "                       labelleft=False, labelbottom=False)\n",
    "        plt.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_quicklooks(deserialized_search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "### Download \n",
    "Now either a single product or multiple products from the search will be downloaded. If the product has already been downloaded it will not load it again, if it is saved in the right workingspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Single Product\n",
    "product = deserialized_search_results[1]\n",
    "path = dag.download(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Boundingbox for Area inside the Tile.\n",
    "latmin, latmax = 48.1, 48.35\n",
    "lonmin, lonmax = 16.1, 16.6\n",
    "extent = {'lonmin': lonmin, 'latmin': latmin, 'lonmax': lonmax, 'latmax': latmax}\n",
    "\n",
    "# Folium Map\n",
    "fmap = folium.Map(location=(np.array([latmin, latmax]).mean(), np.array([lonmin, lonmax]).mean()), zoom_start=9)\n",
    "folium.Rectangle(bounds=[[latmin, lonmin],[latmax, lonmax]], color=\"red\").add_to(fmap)\n",
    "folium.GeoJson(\n",
    "    data=deserialized_search_results[:],  # SearchResult has a __geo_interface__ interface used by folium to get its GeoJSON representation, single results dont work (this [2:3] instead of [2])\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"title\"])\n",
    ").add_to(fmap)\n",
    "fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting common Parameters for all further image processing\n",
    "common_params = dict(\n",
    "    crs=CRS.from_epsg(4326),               # the downloaded images are in 4326, don't reproject them\n",
    "    resolution=0.0006,                     # but lower their resolution (0.0006 should be 60m in 100km)\n",
    "    extent=(lonmin,latmin,lonmax,latmax)   # and zoom over/crop the area of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 \n",
    "### Post Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Bands as Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Level-2A processing includes a Scene Classification and an Atmospheric Correction applied to Top-Of-Atmosphere (TOA) Level-1C orthoimage products. Level-2A main output is an orthoimage atmospherically corrected, Surface Reflectance product.\n",
    "\n",
    "Please be aware that \"Surface Reflectance (SR)\" is a new term that has been introduced to replace the former one: \"Bottom of Atmosphere (BOA) reflectance.\"\n",
    "\n",
    "Additional outputs are an Aerosol Optical Thickness (AOT) map, a Water Vapour (WV) map and a Scene Classification (SCL) map together with Quality Indicators (QI) for cloud and snow probabilities at 60 m resolution. Level-2A output image products are resampled and generated with an equal spatial resolution for all bands (10 m, 20 m or 60 m). Standard distributed products contain the envelope of all resolutions in three distinct folders:\n",
    "\n",
    "\n",
    "- 10 m: containing spectral bands 2, 3, 4 , 8, a True Colour Image (TCI) and an AOT and WVP maps resampled from 20 m.\n",
    "\n",
    "- 20 m: containing spectral bands 1 - 7, the bands 8A, 11 and 12, a True Colour Image (TCI), a Scene Classification (SCL) map and an AOT and WVP map. The band B8 is omitted as B8A provides more precise spectral information.\n",
    "\n",
    "- 60 m: containing all components of the 20 m product resampled to 60 m and additionally the bands 1 and 9, a True Colour Image (TCI), a Scene Classification (SCL) map and an AOT and WVP map. The cirrus band 10 is omitted, as it does not contain surface information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all available Bands (assets)\n",
    "def get_assets(root:str, res=60, only_spectral:bool=True, include_tci:bool=False):\n",
    "    jp2_files = [file for dirs in os.walk(root, topdown=True)\n",
    "                     for file in dirs[2] if file.endswith(f\"_{res}m.jp2\")]\n",
    "    assets = [file.split('_')[2] for file in jp2_files if file.startswith('T')]\n",
    "\n",
    "    if only_spectral and include_tci==False:\n",
    "        assets = [a for a in assets if a[0]=='B']\n",
    "    elif only_spectral and include_tci:\n",
    "        assets = [a for a in assets if a[0] == 'B' or a[0] == 'T']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading data into datasets.\n",
    "\n",
    "def load_single_product(product, bands:list):\n",
    "    loaded_data = {}\n",
    "\n",
    "    for band in bands:\n",
    "        data = product.get_data(band=band, **common_params)\n",
    "        data = data.squeeze()\n",
    "\n",
    "        time_str = product.properties['startTimeFromAscendingNode']\n",
    "        date = dt.datetime.strptime(time_str,'%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "        data = data.expand_dims(dim={'time':[date.date()]})\n",
    "        data.name = band\n",
    "        loaded_data[band] = data\n",
    "    ds = xr.Dataset(loaded_data)\n",
    "    return ds\n",
    "\n",
    "def load_multiple_timestamps(products, bands:list):\n",
    "    single_ds = []\n",
    "    for product in products:\n",
    "        single_product = load_single_product(product=product, bands=bands)\n",
    "        single_ds.append(single_product)\n",
    "\n",
    "    ds = xr.merge(single_ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = get_assets(path, res=10, only_spectral=True, include_tci=False)\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, elem in enumerate(assets):\n",
    "    filepath = product.driver.get_data_address(product, band=elem).split('\\\\')[-5:]\n",
    "    print(idx, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading multiple Bands into a dataset\n",
    "ds = load_single_product(product=product, bands=assets)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = ds.sel(time=dt.datetime(2023, 4, 22), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_to_polygon(path:str) -> list:\n",
    "    '''\n",
    "    Reads a geojson File and returns a List of Polygons \n",
    "\n",
    "    Params:\n",
    "        - ``path``: Filepath to Geojson\n",
    "\n",
    "    Returns: \n",
    "        - ``polygons``: List of Polygons\n",
    "    '''\n",
    "    gdf = gpd.read_file(path)\n",
    "    polygons = [feature for feature in gdf.geometry]\n",
    "    return polygons\n",
    "\n",
    "def geojson_to_polygon_dict(path:str) -> dict:\n",
    "    '''\n",
    "    Uses the Path of a Geojson File to extract the polygons and puts them into a Dictionary.\n",
    "\n",
    "    Params: \n",
    "        - ``path``: Filepath to Geojson\n",
    "\n",
    "    Returns: \n",
    "        - ``polygons_dict``\n",
    "    '''\n",
    "    polygons = geojson_to_polygon(path)\n",
    "    polygons_dict = {idx: [polygon] for idx, polygon in enumerate(polygons)}\n",
    "    return polygons_dict\n",
    "\n",
    "def clip_array(ds:xr.Dataset, polygons):\n",
    "    '''\n",
    "    Takes an xarray.Dataset and a geometry and returns the xarray.Dataset, which has been spatialy clipped\n",
    "    to the geometry.\n",
    "\n",
    "    Params:\n",
    "        - ``ds``: xarray.Dataset\n",
    "        - ``polygons``: shapely.geometry\n",
    "    \n",
    "    Returns:\n",
    "        - ``clipped_nan``: clipped dataset where values outside of polygons have Nan type\n",
    "    '''\n",
    "    clipped = ds.rio.clip(polygons, invert=False, all_touched=False, drop=True)\n",
    "    clipped_nan = clipped.where(clipped == ds)\n",
    "    return clipped_nan\n",
    "\n",
    "def preprocess_data_to_classify(ds:xr.Dataset, feature_path:str, nonfeature_path:str, bands:list=None) -> list:\n",
    "    '''\n",
    "    Takes an xarray Dataset, two geojson files (one of areas with the desired feature, the other not with the feature)\n",
    "    and a list of strings of the desired Bandnames in the Dataset and returns The Training and Test data for some Classifikators.\n",
    "\n",
    "    Params:\n",
    "        - ``ds``: xarray.Dataset\n",
    "        - ``feature_path``: Filepath to Geojson with Polygons, which represent the Feature (e.g.: forested Areas)\n",
    "        - ``nonfeature_path``: Filepath to Geojson, which does not have the feature (e.g.: not forested Areas)\n",
    "        - ``bands`` (optional): List of Strings of desired Spectral Bands (e.g.: bands=['B02', 'B03', 'B04', 'B08'])\n",
    "                                If None, then takes all in the Dataset.\n",
    "\n",
    "    Returns:\n",
    "        -  ``X_train, X_test, y_train, y_test``; Training and Test Split for scikit.learn Classificators\n",
    "    '''\n",
    "    # List all Bands which are loaded as Variables into the Dataset\n",
    "    if bands == None:\n",
    "        bands = list(ds.data_vars)\n",
    "\n",
    "    # Geojsons from Features to Polygons\n",
    "    polygons_feat = geojson_to_polygon_dict(feature_path)\n",
    "    polygons_nonfeat = geojson_to_polygon_dict(nonfeature_path)\n",
    "\n",
    "    # Dictionaries with Dataarrays, each clipped by a Polygon\n",
    "    data_dict_feat = {idx: clip_array(ds, polygon) for idx, polygon in polygons_feat.items()}\n",
    "    data_dict_nonfeat = {idx: clip_array(ds, polygon)  for idx, polygon in polygons_nonfeat.items()}\n",
    "\n",
    "    # Median over time to get rid of outliers\n",
    "    median_data_dict_feat = {idx: xarray.median(dim='time', skipna=True) for idx, xarray in data_dict_feat.items()}\n",
    "    median_data_dict_nonfeat = {idx: xarray.median(dim='time', skipna=True) for idx, xarray in data_dict_nonfeat.items()}\n",
    "\n",
    "    # Reshape the polygon dataarrays to get a tuple (one value per band) of pixel values\n",
    "    feat_data = [xarray.to_array().values.reshape(len(bands),-1).T for xarray in median_data_dict_feat.values()]\n",
    "    nonfeat_data = [xarray.to_array().values.reshape(len(bands),-1).T for xarray in median_data_dict_nonfeat.values()]\n",
    "\n",
    "    # The rows of the different polygons are concatenated to a single array for further processing\n",
    "    feat_values = np.concatenate(feat_data)\n",
    "    nonfeat_values = np.concatenate(nonfeat_data)\n",
    "\n",
    "    # Drop Nan Values\n",
    "    X_feat_data = feat_values[~np.isnan(feat_values).any(axis=1)]\n",
    "    X_nonfeat_data = nonfeat_values[~np.isnan(nonfeat_values).any(axis=1)]\n",
    "\n",
    "    # Creating Output Vector (1 for pixel is features; 0 for pixel is not feature)\n",
    "    y_feat_data = np.ones(X_feat_data.shape[0])\n",
    "    y_nonfeat_data = np.zeros(X_nonfeat_data.shape[0])\n",
    "    \n",
    "    # Concatnate all Classes for training \n",
    "    X = np.concatenate([X_feat_data, X_nonfeat_data])\n",
    "    y = np.concatenate([y_feat_data, y_nonfeat_data])\n",
    "\n",
    "    # Split into Training and Testing Data.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_forest = r'..\\eodag-data\\shpfiles\\forest.geojson'\n",
    "path_nonforest = r'..\\eodag-data\\shpfiles\\nonforest.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_data_to_classify(ds=ds, feature_path=path_forest, nonfeature_path=path_nonforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb_test = nb.fit(X_train, y_train)\n",
    "nb_predict = nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NAIVE BAYES: \\n \"+ classification_report(y_test, nb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NAIVE BAYES: \\n \",confusion_matrix(y_test, nb_predict), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a classifier to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = []\n",
    "for band in ['B04', 'B03', 'B02', 'B08']:\n",
    "    bands.append(single_img[band].values)\n",
    "    \n",
    "image_data = np.stack(bands, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_pixels = single_img.sizes['x'] * single_img.sizes['y']\n",
    "num_of_bands = len(bands)\n",
    "X_image_data = image_data.reshape(num_of_pixels, num_of_bands)\n",
    "\n",
    "nb_predict_img = nb.predict(X_image_data)\n",
    "\n",
    "nb_predict_img = nb_predict_img.reshape(single_img.sizes['y'], single_img.sizes['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap([(1, 0, 0, 0), 'g'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,3))\n",
    "ax.imshow(nb_predict_img, cmap=cmap)\n",
    "ax.set_title(\"naive Bayes\")\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Classification Array to the Dataset. (An already existing band gets \"copied\" and its values get overwritten; there might be better ways, but this is short)\n",
    "ds['NB-forest'] = ds['B02']\n",
    "ds['NB-forest'].values = np.array([nb_predict_img])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(time=dt.datetime(2023, 4, 22), method='nearest')['NB-forest'].plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the True Color Image\n",
    "tci = load_single_product(product=product, bands=['TCI'])\n",
    "tci = tci.sel(time=dt.datetime(2023, 4, 22), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Forest Mask on top of TCI\n",
    "cmap = colors.ListedColormap([(1, 0, 0, 0), 'C0'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "tci['TCI'].plot.imshow(ax=ax, zorder=0)\n",
    "ds.sel(time=dt.datetime(2023, 4, 22), method='nearest')['NB-forest'].plot.imshow(ax=ax, zorder=1, cmap=cmap, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI and many other indices rely on the normalized difference, represented by the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_difference(a, b):\n",
    "    return (a - b*1.)/(a + b) # If b in numerator is not multiplied by 1 as a float some weird things happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the ndvi we need to calculate the normalized difference between the infrared (B08) and the red (B04) band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the NDVI and adding it to the dataset\n",
    "ndvi = normalized_difference(single_img['B08'], single_img['B04'])\n",
    "single_img['NDVI'] = ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img['NDVI'].plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI does a good job seperating vegetation from non-vegetation but it can't seperate forest from vegetated cropland, or grassland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which adds any Index to the dataset might helps keeping your code clean.\n",
    "def add_index_to_dataset(data:xr.Dataset, index:str) -> xr.Dataset:\n",
    "    '''\n",
    "    Takes an xarray Dataset and calculates and adds one of the indices:\n",
    "    \n",
    "    Params:\n",
    "        - ``data``: xarray.Dataset\n",
    "        - ``index``: string (one of [``NDVI``, ``NDMI``, ``MSI``, ``NDWI``])\n",
    "\n",
    "    Returns:\n",
    "        - ``data`` with Index as new Variable\n",
    "    '''\n",
    "    indices = {'NDVI':{'name':'Normalized Diffference Vegetation Index',\n",
    "                       'function':normalized_difference(data['B08'], data['B04'])},\n",
    "            #    'NDMI': {'name':'Normalized Diffference Moisture Index',\n",
    "            #            'function':normalized_difference(data['B08'], data['B11'])},\n",
    "            #    'MSI': {'name':'Moisture Stress Index',\n",
    "            #            'function':data['B11'] / data['B08']},\n",
    "               'NDWI': {'name':'Normalized Diffference Water Index',\n",
    "                       'function':normalized_difference(data['B03'], data['B08'])},}\n",
    "    data[index] = indices[index]['function']\n",
    "    print(f'{indices[index]['name']} ({index}) has been calculated.')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = add_index_to_dataset(ds, index='NDVI')\n",
    "ds = add_index_to_dataset(ds, index='NDWI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['NDWI'].sel(time=dt.datetime(2021, 4, 12), method='nearest').plot.imshow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
