{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import xarray as xr\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from eodag import EODataAccessGateway\n",
    "from eodag import setup_logging\n",
    "\n",
    "from rasterio.crs import CRS\n",
    "from rioxarray.merge import merge_arrays\n",
    "\n",
    "from eotools.shortcut import prepare, configure, deserialize\n",
    "\n",
    "# Setup Verbose Values:\n",
    "# 0: no logging and no progress bar\n",
    "# 1: no logging but progress bars displayed\n",
    "# 2: log at the INFO level\n",
    "# 3: log at the DEBUG level (even more information)\n",
    "\n",
    "setup_logging(verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EODAG - merging\n",
    "\n",
    "EODAG (Earth Observation Data Access Gateway) is a command line tool and a Python package for searching and downloading remotely sensed images while offering a unified API for data access regardless of the data provider.\n",
    "\n",
    "EODAG gives you an easy way to access products from more than 10 providers, with more than 50 different product types (Sentinel 1, Sentinel 2, Sentinel 3, Landsat, etc.) that can be searched and downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "The Lines of Code in this chapter, which essentialy load the data, are not further explained here, since the Notebooks 01 and 02 do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Credentials from .env file and make dirs from paths.yml\n",
    "# These functions are just shortcuts from a python script and just help to keep the notebooks short and simple\n",
    "secrets, ws_paths = prepare(log=False)\n",
    "dag = configure(secrets=secrets, paths=ws_paths)\n",
    "deserialized_search_results = deserialize(filepath=\"search_results.geojson\", ws_path=ws_paths, dag=dag, log=True)\n",
    "\n",
    "# Download multiple Products\n",
    "products = deserialized_search_results\n",
    "paths = dag.download_all(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Boundingbox for Area inside the Tile.\n",
    "latmin, latmax = 48.1, 48.35\n",
    "lonmin, lonmax = 16.1, 16.6\n",
    "extent = {'lonmin': lonmin, 'latmin': latmin, 'lonmax': lonmax, 'latmax': latmax}\n",
    "\n",
    "# Folium Map\n",
    "fmap = folium.Map(location=(np.array([latmin, latmax]).mean(), np.array([lonmin, lonmax]).mean()), zoom_start=9)\n",
    "folium.Rectangle(bounds=[[latmin, lonmin],[latmax, lonmax]], color=\"red\").add_to(fmap)\n",
    "folium.GeoJson(\n",
    "    data=products[:],  # SearchResult has a __geo_interface__ interface used by folium to get its GeoJSON representation, single results dont work (this [2:3] instead of [2])\n",
    "    tooltip=folium.GeoJsonTooltip(fields=[\"title\"])\n",
    ").add_to(fmap)\n",
    "fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting common Parameters for all further image processing\n",
    "common_params = dict(\n",
    "    crs=CRS.from_epsg(4326),               # the downloaded images are in 4326, don't reproject them\n",
    "    resolution=0.0006,                     # but lower their resolution (0.0006 should be 60m in 100km)\n",
    "    extent=(lonmin,latmin,lonmax,latmax)   # and zoom over/crop the area of interest\n",
    ")\n",
    "\n",
    "# Define basic Functions for future operations\n",
    "def normalized_difference(a, b):\n",
    "    return (a - b*1.)/(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Process - Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all available Bands (assets)\n",
    "def get_assets(root:str, res=60):\n",
    "    jp2_files = [file for dirs in os.walk(root, topdown=True)\n",
    "                     for file in dirs[2] if file.endswith(f\"_{res}m.jp2\")]\n",
    "    assets = [file.split('_')[2] for file in jp2_files if file.startswith('T')]\n",
    "    return assets\n",
    "    \n",
    "\n",
    "bands_to_load = get_assets(paths[0], res=10)[1:-1]\n",
    "print(bands_to_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading data into datasets.\n",
    "\n",
    "def load_single_product(product, bands:list):\n",
    "    loaded_data = {}\n",
    "\n",
    "    for band in bands:\n",
    "        data = product.get_data(band=band, **common_params)\n",
    "        data = data.squeeze()\n",
    "\n",
    "        time_str = product.properties['startTimeFromAscendingNode']\n",
    "        date = dt.datetime.strptime(time_str,'%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "        data = data.expand_dims(dim={'time':[date.date()]})\n",
    "        data.name = band\n",
    "        loaded_data[band] = data\n",
    "    ds = xr.Dataset(loaded_data)\n",
    "    return ds\n",
    "\n",
    "def load_multiple_timestamps(products, bands:list):\n",
    "    single_ds = []\n",
    "    for product in products:\n",
    "        single_product = load_single_product(product=product, bands=bands)\n",
    "        single_ds.append(single_product)\n",
    "\n",
    "    ds = xr.merge(single_ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading multiple Bands into a dataset with multiple Timestamps of single Tile\n",
    "\n",
    "tile_33UWP = sorted([p for p in products if 'T33UWP' == p.properties['title'].split('_')[5]], key=lambda p: p.properties[\"title\"].split(\"_\")[2])\n",
    "\n",
    "ds_33UWP = load_multiple_timestamps(products=tile_33UWP, bands=bands_to_load)\n",
    "print(f'This dataset from Tile T33UWP has {len(ds_33UWP.time)} timestamps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading multiple Bands into a dataset with multiple Timestamps of single Tile\n",
    "\n",
    "tile_33UXP = sorted([p for p in products if 'T33UXP' == p.properties['title'].split('_')[5]], key=lambda p: p.properties[\"title\"].split(\"_\")[2])\n",
    "\n",
    "ds_33UXP = load_multiple_timestamps(products=tile_33UXP, bands=bands_to_load)\n",
    "print(f'This dataset from Tile T33UXP has {len(ds_33UXP.time)} timestamps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Merging of the datasets (tile_33UXP and tile_33UWP) (each with multiple timestamps on two different tiles) has not yet been implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging of single Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example two geographicaly overlapping images are merged, and the NDVI is calculated. Note that only Dataarrays are merged but not Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Products \n",
    "products = sorted([p for p in deserialized_search_results], key=lambda p: p.properties[\"title\"].split(\"_\")[2])\n",
    "products[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data of Bands 4 and 8. The Images are from the same time, but different tiles.\n",
    "RED_1 = products[0].get_data(band=\"B04\", **common_params)\n",
    "RED_2 = products[1].get_data(band=\"B04\", **common_params)\n",
    "\n",
    "NIR_1 = products[0].get_data(band=\"B08\", **common_params)\n",
    "NIR_2 = products[1].get_data(band=\"B08\", **common_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using merge_arrays returns the geospatially merged data.\n",
    "merged_red = merge_arrays([RED_1, RED_2], method='max') # methods = ['first', 'last', 'min', 'max', 'sum', 'count']\n",
    "merged_nir = merge_arrays([NIR_1, NIR_2], method='max')\n",
    "\n",
    "merged_ndvi = normalized_difference(merged_nir, merged_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ndvi.plot(cmap='RdYlGn', center=False, size=6, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
