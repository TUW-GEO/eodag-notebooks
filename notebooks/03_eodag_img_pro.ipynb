{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import xarray as xr\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from eodag import EODataAccessGateway\n",
    "from eodag import setup_logging\n",
    "\n",
    "from rasterio.crs import CRS\n",
    "from rioxarray.merge import merge_arrays\n",
    "\n",
    "from eotools.shortcut import prepare, configure, deserialize\n",
    "\n",
    "# Setup Verbose Values:\n",
    "# 0: no logging and no progress bar\n",
    "# 1: no logging but progress bars displayed\n",
    "# 2: log at the INFO level\n",
    "# 3: log at the DEBUG level (even more information)\n",
    "\n",
    "setup_logging(verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "This Notebook intends to show some examples of image processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval/Acquisition\n",
    "The first Lines of Code, which essentialy load the data are not explained, since the Notebooks 01 and 02 do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Credentials from .env file and make dirs from paths.yml\n",
    "# These functions are just shortcuts from a python script and just help to keep the notebooks short and simple\n",
    "secrets, ws_paths = prepare(log=False)\n",
    "dag = configure(secrets=secrets, paths=ws_paths)\n",
    "deserialized_search_results = deserialize(filepath=\"search_results.geojson\", ws_path=ws_paths, dag=dag, log=True)\n",
    "\n",
    "# Download multiple Products\n",
    "products = deserialized_search_results\n",
    "paths = dag.download_all(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Boundingbox for Area inside the Tile.\n",
    "latmin, latmax = 48.1, 48.35\n",
    "lonmin, lonmax = 16.1, 16.6\n",
    "extent = {'lonmin': lonmin, 'latmin': latmin, 'lonmax': lonmax, 'latmax': latmax}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting common Parameters for all further image processing\n",
    "common_params = dict(\n",
    "    crs=CRS.from_epsg(4326),               # the downloaded images are in 4326, don't reproject them\n",
    "    resolution=0.0006,                     # but lower their resolution (0.0006 should be 60m in 100km)\n",
    "    extent=(lonmin,latmin,lonmax,latmax)   # and zoom over/crop the area of interest\n",
    ")\n",
    "\n",
    "# Define basic Functions for future operations\n",
    "def normalized_difference(a, b):\n",
    "    return (a - b*1.)/(a + b)\n",
    "\n",
    "def normalize(a):\n",
    "    return (a - a.min())/(a.max() - a.min())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all available Bands (assets)\n",
    "def get_assets(root:str, res=60):\n",
    "    jp2_files = [file for dirs in os.walk(root, topdown=True)\n",
    "                     for file in dirs[2] if file.endswith(f\"_{res}m.jp2\")]\n",
    "    assets = [file.split('_')[2] for file in jp2_files if file.startswith('T')]\n",
    "    return assets\n",
    "    \n",
    "    \n",
    "assets = get_assets(paths[0], res=10)\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading data into datasets.\n",
    "\n",
    "def load_single_product(product, bands:list):\n",
    "    loaded_data = {}\n",
    "\n",
    "    for band in bands:\n",
    "        data = product.get_data(band=band, **common_params)\n",
    "        data = data.squeeze()\n",
    "\n",
    "        time_str = product.properties['startTimeFromAscendingNode']\n",
    "        date = dt.datetime.strptime(time_str,'%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "        data = data.expand_dims(dim={'time':[date.date()]})\n",
    "        data.name = band\n",
    "        loaded_data[band] = data\n",
    "    ds = xr.Dataset(loaded_data)\n",
    "    return ds\n",
    "\n",
    "def load_multiple_timestamps(products, bands:list):\n",
    "    single_ds = []\n",
    "    for product in products:\n",
    "        single_product = load_single_product(product=product, bands=bands)\n",
    "        single_ds.append(single_product)\n",
    "\n",
    "    ds = xr.merge(single_ds)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Products from same Tile\n",
    "tile_33UWP = sorted([p for p in products if 'T33UWP' == p.properties['title'].split('_')[5]], key=lambda p: p.properties[\"title\"].split(\"_\")[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading multiple Bands into a dataset with multiple Timestamps\n",
    "ds = load_multiple_timestamps(products=tile_33UWP, bands=['B04', 'B03', 'B02', 'B08', 'TCI'])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to display an array, the array needs to have either one or three channels. If there is one color channel the image or array will be displayed as a *black and white* (greyscale) image, but any colormap can be chosen. If the array has three colors each \"layer\" will be interpreted as one of the RGB colors.\n",
    "\n",
    "In this example a single image from the dataset is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single Timestamp from the Dataset (both of the following methods work)\n",
    "single_image = ds.sel(time=dt.datetime(2024, 5, 1), method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the individual bands are extracted from the dataarray and stacked to create an array with shape (x,y,3). Note that Numpy interpretes the first array as red the second as green and the third as blue. It might be natural to stack the bands like that `[b02, b03, b04]`, but this will lead to wrong color interpretations. The Axis defines where the bands should be stacked. If the axis is not set to 2 then the output array will have the shapes (3,x,y) or (x,3,y), both of which will not be properly interpreted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b02 = single_image['B02'].values #blue values\n",
    "b03 = single_image['B03'].values #green values\n",
    "b04 = single_image['B04'].values #red values\n",
    "\n",
    "rgb_raw = np.stack([b04, b03, b02], axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the image can be plotted useing ``matplotlib``. Here the aspect ratio is set to 2, as the longitude (lon) coordinates range from -180 to 180 but the latitude (lat) coordinates just from -90 to 90. Therefore 1° in lon would be similar in lenght to 2° lat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Image\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(rgb_raw, aspect=2)\n",
    "ax.set_title(\"rgb raw\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can clearly see the contrast of the image is very low, which makes it appear very dark. Therefore it is helpful to have a look at the Histograms of the image, to properly get a higher contrast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting an Histogram\n",
    "\n",
    "def histogram(arr, nbins=300, alpha=0.5, figsize=(5,5), title='Histogram'):\n",
    "    #Flatten\n",
    "    flat_r = arr[:, :, 0].flatten()\n",
    "    flat_g = arr[:, :, 1].flatten()\n",
    "    flat_b = arr[:, :, 2].flatten()\n",
    "\n",
    "    # You can set the number of bins and alpha individually\n",
    "    mbins = np.linspace(np.nanmin(arr), np.nanmax(arr), nbins)\n",
    "\n",
    "    # Plot \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.hist(flat_r, color='red', bins=mbins, alpha=alpha)\n",
    "    ax.hist(flat_g, color='green', bins=mbins,  alpha=alpha)\n",
    "    ax.hist(flat_b, color='blue', bins=mbins,  alpha=alpha)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('I')\n",
    "    ax.set_ylabel('n')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(rgb_raw, nbins=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this problem we can increase the contrast of the image. To do this we implement the following functions, which will be needed for processing your image. For more details on how these functions work and why we need them to increase contrast and correctly encode the data, take a look at https://www.cg.tuwien.ac.at/courses/EinfVisComp/Skriptum/SS13/EVC-11%20Point%20Operations.pdf for a great overview. In your own Code it might be helpful, if you put those functions in a Python script and import the script into your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_clip(I, percentile=0.02, pooled=True):\n",
    "    \"\"\" \n",
    "    Calculates the quantiles of I using the percentile parameter and clips the values using the clip function defined below.\n",
    "    \n",
    "    Modifies I\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I : np.array(rows, cols, bands)\n",
    "        Image array.\n",
    "    percentile : float, optional\n",
    "        Percentile defining the clipping boundaries of I in terms of its distribution (defaults to 0.02). \n",
    "    pooled: if True, computes the pooled percentile over all band\n",
    "            (default, use this to keep the relative intensities of the bands for natural looking images)    \n",
    "            if False, computes the percentiles for each band individually\n",
    "            (use this - in conjunction with stretch - to bring the different bands into a comparable range, e.g. for false colour images)\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array : \n",
    "        Auto-clipped image data.\n",
    "    \n",
    "    \"\"\"\n",
    "    if pooled:\n",
    "        v_min = np.nanquantile(I, percentile)\n",
    "        v_max = np.nanquantile(I, 1 - percentile)\n",
    " \n",
    "    else:\n",
    "        tmp = I.reshape(-1, I.shape[-1]) #collapes image x,y 2d-array into a 1d-array\n",
    "        v_min = np.nanquantile(tmp, percentile, axis=0)\n",
    "        v_max = np.nanquantile(tmp, 1 - percentile, axis=0)\n",
    "        \n",
    "    return clip(I, v_min, v_max)        \n",
    "\n",
    "def clip(I, v_min, v_max):\n",
    "    \"\"\" \n",
    "    Performs clipping (dt. \"Histogrammbegrenzung\")\n",
    "    Sets all values in I that are outside of [v_min, v_max] to the corresponding boundary.\n",
    "\n",
    "    \n",
    "    Modifies I\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I : np.array\n",
    "        Image array.\n",
    "    v_min : scalar or array\n",
    "        Lower clipping boundary for each band\n",
    "    v_max : scalar or array\n",
    "        lower clipping boundary for each band\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array : \n",
    "        Clipped image data.\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    tmp = I.reshape(-1, I.shape[-1]) #collapes image x,y 2d-array into a 1d-array         \n",
    "    if np.isscalar(v_min):\n",
    "        tmp[tmp < v_min] = v_min\n",
    "        tmp[tmp > v_max] = v_max\n",
    "    else:\n",
    "        idx = np.where(tmp < v_min)\n",
    "        tmp[idx]=v_min[idx[1]]\n",
    "        idx = np.where(tmp > v_max)\n",
    "        tmp[idx]=v_max[idx[1]]        \n",
    "    \n",
    "    return I\n",
    "            \n",
    "def stretch(I, p_min, p_max, pooled=True):\n",
    "    \"\"\"\n",
    "    Performs histogram stretching or normalisation (dt. \"Spreizung\")\n",
    "    Computes and applies an affine transformation of values in I to the range [p_min, p_max]. \n",
    "    For floating point images to be displayed with pylab.imshow(), p_min=0, p_max=1\n",
    "    should be chosen.\n",
    "    \n",
    "    Modifies I\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    I : np.array\n",
    "        Image array.\n",
    "    p_min : number\n",
    "        Lower boundary of the output range.\n",
    "    p_max : number\n",
    "        Upper  boundary of the output range.\n",
    "    pooled: if True, the transformation is computed for and applied to all bands simultaneously  \n",
    "            if False, -\"- to the individual bands separately\n",
    "    Returns\n",
    "    -------\n",
    "    np.array : \n",
    "        Normalised image data within the range [p_min, p_max].\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    tmp = I.reshape(-1, I.shape[-1]) #collapes image x,y 2d-array into a 1d-array   \n",
    "\n",
    "    if pooled:    \n",
    "        q_min = np.nanmin(I)\n",
    "        q_max = np.nanmax(I)\n",
    "\n",
    "    else:\n",
    "             \n",
    "        q_min = np.nanmin(tmp, axis = 0)\n",
    "        q_max = np.nanmax(tmp, axis = 0)        \n",
    "\n",
    "    tmp[:] =  (p_max - p_min) * (tmp - q_min) / (q_max - q_min) + p_min\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can use the `auto_clip()` or `clip()` function to set values of intensity which are outside of a boundary to the boundary border: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_clipped = auto_clip(rgb_raw.copy(), percentile=0.05, pooled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a histogram with the clipped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(rgb_clipped, nbins=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the histogram now has clear borders, and all the values below/above these borders have been set to the border values. You can play around clipping fewer/more values by setting the percentile value in the `auto_clip()` function. The `pooled` parameter sets if the bands get clipped individually (`=FALSE`) or as a group (`=TRUE`).\n",
    "\n",
    "As the intensity of the values is still too low after clipping we have to stretch the values to spread between 0 and 1. We can do this by using the `stretch()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_clipped_stretched = stretch(rgb_clipped.copy(), 0, 1, pooled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(rgb_clipped_stretched, nbins=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(rgb_clipped_stretched)\n",
    "ax.set_title(\"rgb clipped stretched\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the final image doesnt look natural or still seems too dark try playing around with the percentile value or set the intensity value manually with the `clip()` function instead of `auto_clip()`. If an individual band has a higher intensity compared to the others try setting `pooled` to `=FALSE` when clipping and stretching. \n",
    "\n",
    "You can also use `np.log()` on the raw rgb image before clipping and stretching it to increase contrast.\n",
    "\n",
    "You can see what happens when we play around with the `percentile` parameter in the `auto_clip` function or use the `np.log` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_clipped_stretched_log = stretch(auto_clip(np.log(rgb_raw.copy()), percentile=0.05),0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Color Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to analyze our picture regarding forested areas, we can make this easier using a false color image. Vegetetation reflects light in much higher intensities in the near infrared side of the spectrum. To visualize this we can replace the red band in the rgb image with the NIR band (=band 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the differnt Bands for the False Color Image\n",
    "b02 = single_image['B02'].values #blue values\n",
    "b03 = single_image['B03'].values #green values\n",
    "b08 = single_image['B08'].values #NIR values\n",
    "\n",
    "# Stacking the Bands into a numpy array, which can be interpreted as an RGB Image.\n",
    "fc_img = np.stack([b08, b03, b02], axis=2)\n",
    "fc_img = normalize(fc_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(fc_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(fc_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the NIR values are slightly higher than the ones of the green and blue band. So this time we will change the `pooled` parameter to `False` when incresing the contrast. You can also see the difference when the `pooled` parameter is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_img_clipped_stretched_false = stretch(auto_clip(np.log(fc_img.copy()), pooled = False), 0, 1, pooled = False)\n",
    "\n",
    "fc_img_clipped_stretched_true = stretch(auto_clip(np.log(fc_img.copy()), percentile=0.005, pooled = True), 0, 1, pooled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(fc_img_clipped_stretched_false)\n",
    "histogram(fc_img_clipped_stretched_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to generate an Image which has no clud coverage. To do this we need a few different images from different times. We will then get the median values from each pixel. With this method the Clouds should gone. There might be errors if the selected images all have a very high cloud coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudfree_img = ds.median(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b02 = cloudfree_img['B02'].values\n",
    "b03 = cloudfree_img['B03'].values\n",
    "b04 = cloudfree_img['B04'].values\n",
    "\n",
    "cloudfree_img_raw = np.stack([b04, b03, b02], axis=2)\n",
    "cloudfree_img = stretch(auto_clip(np.log(cloudfree_img_raw)),0,1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(cloudfree_img)\n",
    "ax.set_title(\"Cloudfree image\")\n",
    "ax.set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
