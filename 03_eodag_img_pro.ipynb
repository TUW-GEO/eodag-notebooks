{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import xarray as xr\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from eodag import EODataAccessGateway\n",
    "from eodag import setup_logging\n",
    "\n",
    "from rasterio.crs import CRS\n",
    "from rioxarray.merge import merge_arrays\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Setup Verbose Values:\n",
    "# 0: no logging and no progress bar\n",
    "# 1: no logging but progress bars displayed\n",
    "# 2: log at the INFO level\n",
    "# 3: log at the DEBUG level (even more information)\n",
    "\n",
    "setup_logging(verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying\n",
    "This Notebook intends to show some examples of classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval\n",
    "The first Lines of Code, which essentialy load the data are not explained, since the Notebooks 01 and 02 do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Secrets from .env File\n",
    "secrets = dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Folders for saving Data, serializing and post processing.\n",
    "\n",
    "# Path where the Data should be stored ('c:\\\\Users\\\\theUSER\\\\eodag-data')\n",
    "root = '../eodag-data/'\n",
    "\n",
    "workspace_download = os.path.join(root,'eodag_workspace_download')\n",
    "workspace_serialize = os.path.join(root,'eodag_workspace_serialize_deserialize')\n",
    "workspace_post_process = os.path.join(root,'eodag_workspace_post_process')\n",
    "workspaces = [workspace_download, workspace_serialize, workspace_post_process]\n",
    "\n",
    "for ws in workspaces:\n",
    "    ws = os.path.abspath(ws)\n",
    "    \n",
    "    if not os.path.isdir(ws):\n",
    "        os.mkdir(ws)\n",
    "        print(f'Created Folder: {ws}')\n",
    "    else:\n",
    "        print(f'Folder already exists: {ws}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure\n",
    "#Create EODAG Object and set preferred Provider\n",
    "dag = EODataAccessGateway()\n",
    "dag.set_preferred_provider(\"cop_dataspace\") # Copernicus Data Space Ecosystem\n",
    "\n",
    "dag.update_providers_config(f\"\"\"\n",
    "    cop_dataspace:\n",
    "        download:\n",
    "            outputs_prefix: {os.path.abspath(workspace_download)}\n",
    "        auth:\n",
    "            credentials:\n",
    "                username: {secrets['USER_KEY']}\n",
    "                password: {secrets['USER_SECRET']}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize the Search Results\n",
    "output_file = os.path.join(workspace_serialize, \"search_results.geojson\")\n",
    "deserialized_search_results = dag.deserialize_and_register(output_file)\n",
    "\n",
    "print(f\"Got {len(deserialized_search_results)} deserialized products.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Single Product\n",
    "product = deserialized_search_results[2]\n",
    "path = dag.download(product)\n",
    "\n",
    "# Download multiple Products\n",
    "products = deserialized_search_results[1:3]\n",
    "paths = dag.download_all(products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Boundingbox for Area inside the Tile.\n",
    "latmin, latmax = 48.1, 48.35\n",
    "lonmin, lonmax = 16.1, 16.6\n",
    "extent = {'lonmin': lonmin, 'latmin': latmin, 'lonmax': lonmax, 'latmax': latmax}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting common Parameters for all further image processing\n",
    "common_params = dict(\n",
    "    crs=CRS.from_epsg(4326),               # the downloaded images are in 4326, don't reproject them\n",
    "    resolution=0.0006,                     # but lower their resolution (0.0006 should be 60m in 100km)\n",
    "    extent=(lonmin,latmin,lonmax,latmax)   # and zoom over/crop the area of interest\n",
    ")\n",
    "\n",
    "# Define basic Functions for future operations\n",
    "def normalized_difference(a, b):\n",
    "    return (a - b*1.)/(a + b)\n",
    "\n",
    "def normalize(a):\n",
    "    return (a - a.min())/(a.max() - a.min())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all available Bands (assets)\n",
    "def get_assets(root:str, res=60):\n",
    "    jp2_files = [file for dirs in os.walk(root, topdown=True)\n",
    "                     for file in dirs[2] if file.endswith(f\"_{res}m.jp2\")]\n",
    "    assets = [file.split('_')[2] for file in jp2_files if file.startswith('T')]\n",
    "    return assets\n",
    "    \n",
    "    \n",
    "assets = get_assets(path, res=10)\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading data into datasets.\n",
    "\n",
    "def load_single_product(product, bands:list):\n",
    "    loaded_data = {}\n",
    "\n",
    "    for band in bands:\n",
    "        data = product.get_data(band=band, **common_params)\n",
    "        data = data.squeeze()\n",
    "\n",
    "        time_str = product.properties['startTimeFromAscendingNode']\n",
    "        date = dt.datetime.strptime(time_str,'%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "        data = data.expand_dims(dim={'time':[date.date()]})\n",
    "        data.name = band\n",
    "        loaded_data[band] = data\n",
    "    ds = xr.Dataset(loaded_data)\n",
    "    return ds\n",
    "\n",
    "def load_multiple_timestamps(products, bands:list):\n",
    "    loaded_data = {}\n",
    "    # Combine multiple Dataarrays into one Dataset\n",
    "    for band in bands:\n",
    "        single_band_ts = []\n",
    "        # Load one Band of each product and concat them into an xarray Dataarray\n",
    "        for prod in products: \n",
    "            data = prod.get_data(band=band, **common_params)\n",
    "            data = data.squeeze()\n",
    "\n",
    "            time_str = prod.properties['startTimeFromAscendingNode'][:-1] #Remove Timezone info\n",
    "            date = pd.to_datetime([time_str])\n",
    "\n",
    "            data = data.expand_dims(time=date)\n",
    "            data.name = band\n",
    "            single_band_ts.append(data)\n",
    "            \n",
    "        ts =  xr.concat(single_band_ts, dim='time')\n",
    "        loaded_data[band] = ts   \n",
    "\n",
    "    ds = xr.Dataset(loaded_data)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading multiple Bands into a dataset with multiple Timestamps\n",
    "ds = load_multiple_timestamps(products=products, bands=['B04', 'B03', 'B02', 'B08', 'TCI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Color Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single Timestamp from the Dataset (both of the following methods work)\n",
    "\n",
    "single_image = ds.sel(time=dt.datetime(2023, 3, 16), method='nearest')\n",
    "#single_image = ds.sel(time='2023-03-16', method='nearest')\n",
    "\n",
    "#single_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the differnt Bands for the False Color Image\n",
    "b02 = single_image['B02'].values #blue values\n",
    "b03 = single_image['B03'].values #green values\n",
    "b08 = single_image['B08'].values #NIR values\n",
    "\n",
    "# Stacking the Bands into a numpy array, which can be interpreted as an RGB Image.\n",
    "fc_img = np.stack([b08, b03, b02], axis=2)\n",
    "fc_img = normalize(fc_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(fc_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
